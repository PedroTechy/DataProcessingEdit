{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PedroTechy/DataProcessingEdit/blob/main/spark/examples/05-aggregations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-y331t1OSI1s"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lucprosa/dataeng-basic-course/blob/main/spark/examples/05-aggregations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOA_wQSmLd9z"
      },
      "source": [
        "# Aggregations\n",
        "- Group By\n",
        "- Windows Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9LeYFsPTjAb"
      },
      "source": [
        "# Setting up PySpark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYXeODL0T1fO",
        "outputId": "0a468436-dde8-43aa-b621-f939eeba6045"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.3)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "# @title\n",
        "%pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "637HFw00T3LP"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master('local').appName('Spark Course').config('spark.ui.port', '4050').getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLiYPwuJSI1w"
      },
      "source": [
        "# Aggregations\n",
        "\n",
        "https://spark.apache.org/docs/latest/sql-ref-functions-builtin.html#aggregate-functions\n",
        "\n",
        "https://spark.apache.org/docs/latest/sql-ref-syntax-qry-select-aggregate.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPdtlX5BSI1w",
        "outputId": "87daf67f-0c5b-494c-c842-080be742026e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+----------+------+\n",
            "|    employee_name|department|salary|\n",
            "+-----------------+----------+------+\n",
            "|     Diane Murphy|Accounting|  8435|\n",
            "|   Mary Patterson|Accounting|  9998|\n",
            "|    Jeff Firrelli|Accounting|  8992|\n",
            "|William Patterson|Accounting|  8870|\n",
            "|    Gerard Bondur|Accounting| 11472|\n",
            "|      Anthony Bow|Accounting|  6627|\n",
            "|  Leslie Jennings|        IT|  8113|\n",
            "|  Leslie Thompson|        IT|  5186|\n",
            "|   Julie Firrelli|     Sales|  9181|\n",
            "|  Steve Patterson|     Sales|  9441|\n",
            "|   Foon Yue Tseng|     Sales|  6660|\n",
            "|    George Vanauf|     Sales| 10563|\n",
            "|      Loui Bondur|       SCM| 10449|\n",
            "| Gerard Hernandez|       SCM|  6949|\n",
            "|  Pamela Castillo|       SCM| 11303|\n",
            "|       Larry Bott|       SCM| 11798|\n",
            "|      Barry Jones|       SCM| 10586|\n",
            "+-----------------+----------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sql_query = \"\"\"CREATE OR REPLACE TEMPORARY VIEW basic_pays AS SELECT * FROM VALUES\n",
        "('Diane Murphy','Accounting',8435),\n",
        "('Mary Patterson','Accounting',9998),\n",
        "('Jeff Firrelli','Accounting',8992),\n",
        "('William Patterson','Accounting',8870),\n",
        "('Gerard Bondur','Accounting',11472),\n",
        "('Anthony Bow','Accounting',6627),\n",
        "('Leslie Jennings','IT',8113),\n",
        "('Leslie Thompson','IT',5186),\n",
        "('Julie Firrelli','Sales',9181),\n",
        "('Steve Patterson','Sales',9441),\n",
        "('Foon Yue Tseng','Sales',6660),\n",
        "('George Vanauf','Sales',10563),\n",
        "('Loui Bondur','SCM',10449),\n",
        "('Gerard Hernandez','SCM',6949),\n",
        "('Pamela Castillo','SCM',11303),\n",
        "('Larry Bott','SCM',11798),\n",
        "('Barry Jones','SCM',10586)\n",
        "AS basic_pays(employee_name, department, salary)\"\"\"\n",
        "\n",
        "# creating temp view\n",
        "spark.sql(sql_query)\n",
        "\n",
        "df = spark.table(\"basic_pays\")\n",
        "df.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8aWbknF9eKPH"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "perc_query = \"\"\"SELECT\n",
        "    department,\n",
        "    percentile_cont(0.25) WITHIN GROUP (ORDER BY salary) AS pc1,\n",
        "    percentile_cont(0.25) WITHIN GROUP (ORDER BY salary) FILTER (WHERE employee_name LIKE '%Bo%') AS pc2,\n",
        "    percentile_cont(0.25) WITHIN GROUP (ORDER BY salary DESC) AS pc3,\n",
        "    percentile_cont(0.25) WITHIN GROUP (ORDER BY salary DESC) FILTER (WHERE employee_name LIKE '%Bo%') AS pc4,\n",
        "    percentile_disc(0.25) WITHIN GROUP (ORDER BY salary) AS pd1,\n",
        "    percentile_disc(0.25) WITHIN GROUP (ORDER BY salary) FILTER (WHERE employee_name LIKE '%Bo%') AS pd2,\n",
        "    percentile_disc(0.25) WITHIN GROUP (ORDER BY salary DESC) AS pd3,\n",
        "    percentile_disc(0.25) WITHIN GROUP (ORDER BY salary DESC) FILTER (WHERE employee_name LIKE '%Bo%') AS pd4\n",
        "FROM basic_pays\n",
        "GROUP BY department\n",
        "ORDER BY department;\"\"\"\n",
        "\n",
        "spark.sql(perc_query).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aa38HFEQVSM9",
        "outputId": "122b5a1d-7257-490b-8b6b-bef72edced82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-------+--------+-------+--------+-------+-------+-------+-------+\n",
            "|department|    pc1|     pc2|    pc3|     pc4|    pd1|    pd2|    pd3|    pd4|\n",
            "+----------+-------+--------+-------+--------+-------+-------+-------+-------+\n",
            "|Accounting|8543.75| 7838.25| 9746.5|10260.75| 8435.0| 6627.0| 9998.0|11472.0|\n",
            "|        IT|5917.75|    NULL|7381.25|    NULL| 5186.0|   NULL| 8113.0|   NULL|\n",
            "|       SCM|10449.0|10786.25|11303.0|11460.75|10449.0|10449.0|11303.0|11798.0|\n",
            "|     Sales|8550.75|    NULL| 9721.5|    NULL| 6660.0|   NULL|10563.0|   NULL|\n",
            "+----------+-------+--------+-------+--------+-------+-------+-------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import *\n",
        "(df\n",
        " .groupBy(\"department\")\n",
        " .agg(sum(\"salary\").alias(\"sum_salary\"),\n",
        "      round(avg(\"salary\"),2).alias(\"avg_salary\"),\n",
        "      min(\"salary\").alias(\"min_salary\"),\n",
        "      array_agg(\"employee_name\").alias(\"employees\"),\n",
        "      count(lit(\"\")).alias(\"count_employees\"))\n",
        " .filter(col(\"count_employees\") > 2)\n",
        " .show(10, False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZbfHHI_wYJge",
        "outputId": "825d8350-66c6-47d7-a726-349baa55ad91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----------+----------+----------+--------------------------------------------------------------------------------------------+---------------+\n",
            "|department|sum_salary|avg_salary|min_salary|employees                                                                                   |count_employees|\n",
            "+----------+----------+----------+----------+--------------------------------------------------------------------------------------------+---------------+\n",
            "|Sales     |35845     |8961.25   |6660      |[Julie Firrelli, Steve Patterson, Foon Yue Tseng, George Vanauf]                            |4              |\n",
            "|Accounting|54394     |9065.67   |6627      |[Diane Murphy, Mary Patterson, Jeff Firrelli, William Patterson, Gerard Bondur, Anthony Bow]|6              |\n",
            "|SCM       |51085     |10217.0   |6949      |[Loui Bondur, Gerard Hernandez, Pamela Castillo, Larry Bott, Barry Jones]                   |5              |\n",
            "+----------+----------+----------+----------+--------------------------------------------------------------------------------------------+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question"
      ],
      "metadata": {
        "id": "HQjSVZgFbiUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Q1\n",
        "# Aggregate data by surname\n",
        "# Calculate highest salary by surname\n",
        "# Include the respective employee that has the highest salary\n",
        "# Include department information about this employee\n",
        "# Count how many employees has that surname\n",
        "# Put in an array all the first_names of the respective surname ordered\n",
        "\n",
        "\n",
        "from pyspark.sql import functions as F\n",
        "\n",
        "#Added column \"surname\" to my dataframe based on the col emplyoee_name\n",
        "df = df.withColumn(\"surname\", split(col(\"employee_name\"), \" \")[1])\n",
        "df = df.withColumn(\"first_name\", split(col(\"employee_name\"), \" \")[0])\n",
        "\n",
        "df_temp = df.groupBy(\"surname\").agg(\n",
        "    F.max(\"salary\").alias(\"max_salary_by_surname\"),\n",
        "    F.count(lit(\" \")).alias(\"count_employees_for_surname\"),\n",
        "    F.array_agg(\"first_name\").alias(\"first_names\"),\n",
        "    filter(col(\"first_names\"))\n",
        ")\n",
        "df_temp.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# schema expected:\n",
        "# surname | count_employees | highest_salary | employee_with_highest_salary | department_with_highest_salary | array_with_all_the_first_names |"
      ],
      "metadata": {
        "id": "sAB_dzZabf_o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5387cf78-230e-410e-e240-693dab5a0268"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------------------+---------------------------+--------------------+\n",
            "|  surname|max_salary_by_surname|count_employees_for_surname|          firt_names|\n",
            "+---------+---------------------+---------------------------+--------------------+\n",
            "|      Bow|                 6627|                          1|           [Anthony]|\n",
            "|    Jones|                10586|                          1|             [Barry]|\n",
            "|   Bondur|                11472|                          2|      [Gerard, Loui]|\n",
            "|   Murphy|                 8435|                          1|             [Diane]|\n",
            "| Castillo|                11303|                          1|            [Pamela]|\n",
            "| Firrelli|                 9181|                          2|       [Jeff, Julie]|\n",
            "|   Vanauf|                10563|                          1|            [George]|\n",
            "|      Yue|                 6660|                          1|              [Foon]|\n",
            "|Patterson|                 9998|                          3|[Mary, William, S...|\n",
            "| Thompson|                 5186|                          1|            [Leslie]|\n",
            "| Jennings|                 8113|                          1|            [Leslie]|\n",
            "|     Bott|                11798|                          1|             [Larry]|\n",
            "|Hernandez|                 6949|                          1|            [Gerard]|\n",
            "+---------+---------------------+---------------------------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Split the employee_name into first_name and surname\n",
        "df = df.withColumn(\"first_name\", split(col(\"employee_name\"), \" \").getItem(0)) \\\n",
        "       .withColumn(\"surname\", split(col(\"employee_name\"), \" \").getItem(1))\n",
        "\n",
        "# Get the highest salary for each surname and the employee with the highest salary\n",
        "window_spec = Window.partitionBy(\"surname\").orderBy(F.desc(\"salary\"))\n",
        "\n",
        "df_with_highest = df.withColumn(\"row_number\", F.row_number().over(window_spec)) \\\n",
        "                    .filter(F.col(\"row_number\") == 1) \\\n",
        "                    .select(\"surname\", \"salary\", \"employee_name\", \"department\") \\\n",
        "                    .withColumnRenamed(\"salary\", \"highest_salary\") \\\n",
        "                    .withColumnRenamed(\"employee_name\", \"employee_with_highest_salary\") \\\n",
        "                    .withColumnRenamed(\"department\", \"department_with_highest_salary\")\n",
        "\n",
        "# Aggregate data by surname\n",
        "result = df.groupBy(\"surname\") \\\n",
        "           .agg(F.count(\"surname\").alias(\"count_employees\"),\n",
        "                F.collect_list(\"first_name\").alias(\"first_names\")) \\\n",
        "           .join(df_with_highest, on=\"surname\") \\\n",
        "           .withColumn(\"array_with_all_the_first_names\", F.expr(\"sort_array(first_names)\"))\n",
        "\n",
        "# Select and order the final columns\n",
        "result.select(\"surname\",\n",
        "              \"count_employees\",\n",
        "              \"highest_salary\",\n",
        "              \"employee_with_highest_salary\",\n",
        "              \"department_with_highest_salary\",\n",
        "              \"array_with_all_the_first_names\").show(truncate=False)\n"
      ],
      "metadata": {
        "id": "PIq6uQGHgk7-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}